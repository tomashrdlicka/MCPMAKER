// ============================================================
// MCPMAKER Engine - MCP Server Generator
// Generates a standalone MCP server from a WorkflowDefinition
// ============================================================

import { mkdirSync, writeFileSync, chmodSync, existsSync } from 'node:fs';
import { join } from 'node:path';
import { execSync, spawn } from 'node:child_process';
import type { WorkflowDefinition, WorkflowStep, ParameterDef, StepInputMapping } from './types.js';
import { getMcpmakerDir } from './database.js';

// ---- Directory Setup ----

function sanitizeName(name: string): string {
  return name
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-|-$/g, '');
}

function getServerDir(workflowName: string): string {
  return join(getMcpmakerDir(), 'servers', sanitizeName(workflowName));
}

// ---- File Generators ----

function generatePackageJson(workflowName: string): string {
  const safeName = sanitizeName(workflowName);
  return JSON.stringify(
    {
      name: `@mcpmaker/server-${safeName}`,
      version: '1.0.0',
      private: true,
      type: 'module',
      main: './server.js',
      scripts: {
        start: 'node server.js',
      },
      dependencies: {
        '@modelcontextprotocol/sdk': '^1.0.0',
      },
    },
    null,
    2
  );
}

function generateGitignore(): string {
  return `config.json
node_modules/
`;
}

function generateConfigJson(definition: WorkflowDefinition): string {
  const config: Record<string, string> = {};

  for (const field of definition.auth.credentialFields) {
    config[field.name] = `REPLACE_WITH_${field.name.toUpperCase()}`;
  }

  return JSON.stringify(config, null, 2);
}

function generateServerJs(definition: WorkflowDefinition): string {
  const toolName = sanitizeName(definition.name);
  const inputSchemaProperties: Record<string, { type: string; description: string }> = {};
  const requiredParams: string[] = [];

  for (const param of definition.parameters) {
    inputSchemaProperties[param.name] = {
      type: param.type,
      description: param.description,
    };
    if (param.required) {
      requiredParams.push(param.name);
    }
  }

  // Build step execution code
  const stepExecutions = definition.steps.map((step, i) => generateStepExecution(step, i, definition));

  // Identify parallel groups
  const parallelGroups = identifyParallelGroups(definition.steps);

  return `#!/usr/bin/env node
// ============================================================
// MCP Server: ${definition.name}
// ${definition.description}
// Generated by MCPMAKER
// ============================================================

import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from '@modelcontextprotocol/sdk/types.js';
import { readFileSync } from 'node:fs';
import { join, dirname } from 'node:path';
import { fileURLToPath } from 'node:url';

const __dirname = dirname(fileURLToPath(import.meta.url));

// Load auth credentials
let credentials = {};
try {
  const configPath = join(__dirname, 'config.json');
  credentials = JSON.parse(readFileSync(configPath, 'utf-8'));
} catch (e) {
  console.error('Warning: Could not load config.json. Auth credentials may be missing.');
}

// Load workflow definition
let workflow;
try {
  const workflowPath = join(__dirname, 'workflow.json');
  workflow = JSON.parse(readFileSync(workflowPath, 'utf-8'));
} catch (e) {
  console.error('Error: Could not load workflow.json');
  process.exit(1);
}

const BASE_URL = ${JSON.stringify(definition.baseUrl)};

// ---- HTTP Helpers ----

async function makeRequest(method, path, headers, body, queryParams) {
  let url = BASE_URL + path;

  if (queryParams && Object.keys(queryParams).length > 0) {
    const searchParams = new URLSearchParams();
    for (const [key, value] of Object.entries(queryParams)) {
      if (value !== undefined && value !== null) {
        searchParams.set(key, String(value));
      }
    }
    url += '?' + searchParams.toString();
  }

  const fetchOptions = {
    method,
    headers: {
      'Content-Type': 'application/json',
      ...headers,
    },
  };

  if (body && method !== 'GET' && method !== 'HEAD') {
    fetchOptions.body = typeof body === 'string' ? body : JSON.stringify(body);
  }

  const response = await fetch(url, fetchOptions);

  let responseBody;
  const contentType = response.headers.get('content-type') || '';
  if (contentType.includes('application/json')) {
    responseBody = await response.json();
  } else {
    responseBody = await response.text();
  }

  if (!response.ok) {
    throw new Error(\`HTTP \${response.status}: \${typeof responseBody === 'string' ? responseBody : JSON.stringify(responseBody)}\`);
  }

  return responseBody;
}

function resolveTemplate(template, params, stepResults) {
  if (!template) return template;
  let result = typeof template === 'string' ? template : JSON.stringify(template);

  // Replace parameter placeholders
  for (const [key, value] of Object.entries(params)) {
    result = result.replace(new RegExp(\`\\\\{\${key}\\\\}\`, 'g'), String(value));
  }

  // Replace step result references
  for (const [stepKey, stepValue] of Object.entries(stepResults)) {
    if (typeof stepValue === 'object' && stepValue !== null) {
      for (const [field, val] of Object.entries(stepValue)) {
        result = result.replace(
          new RegExp(\`\\\\{step\${stepKey}\\.\${field}\\\\}\`, 'g'),
          String(val)
        );
      }
    }
  }

  return result;
}

function getValueByJsonPath(obj, jsonPath) {
  if (!obj || !jsonPath) return undefined;

  // Remove leading $. if present
  const path = jsonPath.startsWith('$.') ? jsonPath.substring(2) : jsonPath;
  const parts = path.split(/[.\\[\\]]/).filter(Boolean);

  let current = obj;
  for (const part of parts) {
    if (current === null || current === undefined) return undefined;
    current = current[part];
  }

  return current;
}

function applyInputMappings(mappings, stepResults, currentValue) {
  if (!mappings || mappings.length === 0) return currentValue;

  for (const mapping of mappings) {
    const sourceResult = stepResults[mapping.sourceStep];
    if (!sourceResult) continue;

    const value = getValueByJsonPath(sourceResult, mapping.sourceJsonPath);
    if (value === undefined) continue;

    if (mapping.targetLocation === 'path') {
      if (typeof currentValue === 'string') {
        currentValue = currentValue.replace(\`{\${mapping.targetKey}}\`, String(value));
      }
    } else if (mapping.targetLocation === 'query') {
      if (typeof currentValue === 'object' && currentValue !== null) {
        currentValue[mapping.targetKey] = String(value);
      }
    } else if (mapping.targetLocation === 'body') {
      if (typeof currentValue === 'object' && currentValue !== null) {
        setNestedValue(currentValue, mapping.targetKey, value);
      }
    } else if (mapping.targetLocation === 'header') {
      if (typeof currentValue === 'object' && currentValue !== null) {
        currentValue[mapping.targetKey] = String(value);
      }
    }
  }

  return currentValue;
}

function setNestedValue(obj, path, value) {
  const parts = path.split('.');
  let current = obj;
  for (let i = 0; i < parts.length - 1; i++) {
    if (!(parts[i] in current)) {
      current[parts[i]] = {};
    }
    current = current[parts[i]];
  }
  current[parts[parts.length - 1]] = value;
}

function applyAuthCredentials(headers) {
  const result = { ...headers };
${generateAuthApplication(definition)}
  return result;
}

// ---- Execute Workflow ----

async function executeWorkflow(params) {
  const stepResults = {};

${generateExecutionCode(definition, parallelGroups)}

  // Extract return values
  const returnData = {};
${generateReturnExtraction(definition)}

  return returnData;
}

// ---- MCP Server Setup ----

const server = new Server(
  {
    name: '${toolName}',
    version: '1.0.0',
  },
  {
    capabilities: {
      tools: {},
    },
  }
);

server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: ${JSON.stringify(toolName)},
        description: ${JSON.stringify(definition.description)},
        inputSchema: {
          type: 'object',
          properties: ${JSON.stringify(inputSchemaProperties, null, 10)},
          required: ${JSON.stringify(requiredParams)},
        },
      },
    ],
  };
});

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  if (request.params.name !== ${JSON.stringify(toolName)}) {
    return {
      content: [
        {
          type: 'text',
          text: \`Unknown tool: \${request.params.name}\`,
        },
      ],
      isError: true,
    };
  }

  try {
    const result = await executeWorkflow(request.params.arguments || {});
    return {
      content: [
        {
          type: 'text',
          text: JSON.stringify(result, null, 2),
        },
      ],
    };
  } catch (error) {
    return {
      content: [
        {
          type: 'text',
          text: \`Error executing workflow: \${error.message}\`,
        },
      ],
      isError: true,
    };
  }
});

// Start server
const transport = new StdioServerTransport();
await server.connect(transport);
console.error(\`MCP Server "${definition.name}" running on stdio\`);
`;
}

// ---- Code Generation Helpers ----

function generateStepExecution(step: WorkflowStep, index: number, definition: WorkflowDefinition): string {
  return `
  // Step ${step.order}: ${step.description}
  {
    let path = resolveTemplate(${JSON.stringify(step.request.pathTemplate)}, params, stepResults);
    let headers = { ...applyAuthCredentials(${JSON.stringify(step.request.headers)}) };
    let queryParams = ${step.request.queryTemplate ? `{ ...${JSON.stringify(step.request.queryTemplate)} }` : '{}'};
    let body = ${step.request.bodyTemplate ? `JSON.parse(resolveTemplate(${JSON.stringify(step.request.bodyTemplate)}, params, stepResults))` : 'undefined'};

    // Apply input mappings from previous steps
    ${step.inputMappings.length > 0 ? `
    path = applyInputMappings(${JSON.stringify(step.inputMappings.filter(m => m.targetLocation === 'path'))}, stepResults, path);
    queryParams = applyInputMappings(${JSON.stringify(step.inputMappings.filter(m => m.targetLocation === 'query'))}, stepResults, queryParams);
    if (body) body = applyInputMappings(${JSON.stringify(step.inputMappings.filter(m => m.targetLocation === 'body'))}, stepResults, body);
    headers = applyInputMappings(${JSON.stringify(step.inputMappings.filter(m => m.targetLocation === 'header'))}, stepResults, headers);
    ` : ''}
    // Resolve any remaining parameter placeholders in query params
    for (const [key, value] of Object.entries(queryParams)) {
      queryParams[key] = resolveTemplate(String(value), params, stepResults);
    }

    stepResults[${step.order}] = await makeRequest(
      ${JSON.stringify(step.request.method)},
      path,
      headers,
      body,
      Object.keys(queryParams).length > 0 ? queryParams : undefined
    );
  }`;
}

function identifyParallelGroups(steps: WorkflowStep[]): Map<number, number[]> {
  const groups = new Map<number, number[]>();

  // Group steps by their dependency
  const depGroups = new Map<number | undefined, number[]>();
  for (const step of steps) {
    const dep = step.dependsOn;
    const group = depGroups.get(dep) || [];
    group.push(step.order);
    depGroups.set(dep, group);
  }

  // Only keep groups with 2+ steps
  let groupIdx = 0;
  for (const [, stepOrders] of depGroups) {
    if (stepOrders.length >= 2) {
      groups.set(groupIdx++, stepOrders);
    }
  }

  return groups;
}

function generateExecutionCode(definition: WorkflowDefinition, parallelGroups: Map<number, number[]>): string {
  const parallelSteps = new Set<number>();
  for (const [, steps] of parallelGroups) {
    for (const s of steps) {
      parallelSteps.add(s);
    }
  }

  const lines: string[] = [];
  const processedSteps = new Set<number>();

  // Process steps in order, grouping parallel ones
  for (const step of definition.steps) {
    if (processedSteps.has(step.order)) continue;

    // Check if this step is part of a parallel group
    let isInParallelGroup = false;
    for (const [, groupSteps] of parallelGroups) {
      if (groupSteps.includes(step.order) && !processedSteps.has(groupSteps[0])) {
        // Execute this group in parallel
        isInParallelGroup = true;

        const stepsInGroup = groupSteps
          .map((so) => definition.steps.find((s) => s.order === so))
          .filter((s): s is WorkflowStep => s !== undefined);

        if (stepsInGroup.length > 1) {
          lines.push(`  // Steps ${groupSteps.join(', ')} can run in parallel`);
          lines.push(`  await Promise.all([`);

          for (const gs of stepsInGroup) {
            lines.push(`    (async () => {`);
            lines.push(generateStepExecution(gs, gs.order, definition));
            lines.push(`    })(),`);
            processedSteps.add(gs.order);
          }

          lines.push(`  ]);`);
        } else {
          // Only one step, execute sequentially
          lines.push(generateStepExecution(step, step.order, definition));
          processedSteps.add(step.order);
        }

        break;
      }
    }

    if (!isInParallelGroup && !processedSteps.has(step.order)) {
      lines.push(generateStepExecution(step, step.order, definition));
      processedSteps.add(step.order);
    }
  }

  return lines.join('\n');
}

function generateAuthApplication(definition: WorkflowDefinition): string {
  const lines: string[] = [];

  for (const field of definition.auth.credentialFields) {
    switch (field.location) {
      case 'header':
        if (definition.auth.type === 'bearer') {
          lines.push(`  if (credentials.${field.name}) {`);
          lines.push(`    result['Authorization'] = 'Bearer ' + credentials.${field.name};`);
          lines.push(`  }`);
        } else {
          lines.push(`  if (credentials.${field.name}) {`);
          lines.push(`    result['${field.name}'] = credentials.${field.name};`);
          lines.push(`  }`);
        }
        break;
      case 'cookie':
        lines.push(`  if (credentials.${field.name}) {`);
        lines.push(`    const existingCookie = result['Cookie'] || '';`);
        lines.push(`    result['Cookie'] = existingCookie ? existingCookie + '; ${field.name}=' + credentials.${field.name} : '${field.name}=' + credentials.${field.name};`);
        lines.push(`  }`);
        break;
      case 'query':
        // Query params are handled in the execution code
        lines.push(`  // Note: ${field.name} is passed as a query parameter in each request`);
        break;
    }
  }

  return lines.join('\n');
}

function generateReturnExtraction(definition: WorkflowDefinition): string {
  const lines: string[] = [];

  for (const field of definition.returns.fields) {
    lines.push(
      `  returnData[${JSON.stringify(field.name)}] = getValueByJsonPath(stepResults[${field.source.step}], ${JSON.stringify(field.source.jsonPath)});`
    );
  }

  return lines.join('\n');
}

// ---- Public API ----

export interface GenerateResult {
  serverPath: string;
  error?: string;
}

export function generateMcpServer(definition: WorkflowDefinition): GenerateResult {
  const serverDir = getServerDir(definition.name);

  try {
    // Create directory structure
    mkdirSync(serverDir, { recursive: true });

    // Generate all files
    writeFileSync(join(serverDir, 'package.json'), generatePackageJson(definition.name));
    writeFileSync(join(serverDir, 'server.js'), generateServerJs(definition));
    writeFileSync(join(serverDir, 'workflow.json'), JSON.stringify(definition, null, 2));
    writeFileSync(join(serverDir, '.gitignore'), generateGitignore());

    // Generate config.json with restricted permissions
    const configPath = join(serverDir, 'config.json');
    writeFileSync(configPath, generateConfigJson(definition));
    try {
      chmodSync(configPath, 0o600);
    } catch {
      // chmod may fail on some systems, not critical
    }

    // Install dependencies
    try {
      execSync('npm install --production', {
        cwd: serverDir,
        timeout: 60000,
        stdio: 'pipe',
      });
    } catch (installError) {
      console.warn('npm install failed, server may need manual dependency installation:', (installError as Error).message);
    }

    return { serverPath: serverDir };
  } catch (error) {
    return {
      serverPath: serverDir,
      error: `Failed to generate MCP server: ${(error as Error).message}`,
    };
  }
}

export interface ServerStatus {
  running: boolean;
  pid?: number;
  error?: string;
}

// Track running server processes
const runningServers = new Map<string, { process: ReturnType<typeof spawn>; pid: number }>();

export function startMcpServer(serverPath: string): ServerStatus {
  // Check if already running
  const existing = runningServers.get(serverPath);
  if (existing) {
    try {
      // Check if process is still alive
      process.kill(existing.pid, 0);
      return { running: true, pid: existing.pid };
    } catch {
      // Process is dead, clean up
      runningServers.delete(serverPath);
    }
  }

  const serverJs = join(serverPath, 'server.js');
  if (!existsSync(serverJs)) {
    return { running: false, error: 'server.js not found in server directory' };
  }

  try {
    const child = spawn('node', [serverJs], {
      cwd: serverPath,
      stdio: ['pipe', 'pipe', 'pipe'],
      detached: true,
    });

    child.unref();

    if (child.pid) {
      runningServers.set(serverPath, { process: child, pid: child.pid });

      child.on('exit', () => {
        runningServers.delete(serverPath);
      });

      return { running: true, pid: child.pid };
    }

    return { running: false, error: 'Failed to start server process' };
  } catch (error) {
    return { running: false, error: `Failed to start server: ${(error as Error).message}` };
  }
}

export function stopMcpServer(serverPath: string): void {
  const existing = runningServers.get(serverPath);
  if (existing) {
    try {
      process.kill(existing.pid, 'SIGTERM');
    } catch {
      // Process may already be dead
    }
    runningServers.delete(serverPath);
  }
}

export function getMcpServerStatus(serverPath: string): ServerStatus {
  const existing = runningServers.get(serverPath);
  if (!existing) {
    return { running: false };
  }

  try {
    process.kill(existing.pid, 0);
    return { running: true, pid: existing.pid };
  } catch {
    runningServers.delete(serverPath);
    return { running: false };
  }
}
